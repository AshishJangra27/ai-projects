{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2l6mprX8xtF"
      },
      "source": [
        "# Transfer Learning with Pre-trained Models on CIFAR-100\n",
        "\n",
        "## Introduction\n",
        "This notebook demonstrates the use of transfer learning with various pre-trained models to classify images from the CIFAR-100 dataset. We will leverage architectures such as ResNet50, VGG16, and MobileNetV2 that have been pre-trained on ImageNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsZFaJzx8xtH"
      },
      "source": [
        "## 1. Data Loading and Preprocessing\n",
        "Load the CIFAR-100 dataset and prepare it for transfer learning by applying appropriate preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-wi1GdT8xtH",
        "outputId": "bbd6cd3e-3651-4186-a1c8-c6c3176e0df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet50\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg16\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_mobilenetv2\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "X_train_resnet50 = preprocess_resnet50(X_train)\n",
        "X_test_resnet50 = preprocess_resnet50(X_test)\n",
        "\n",
        "X_train_vgg16 = preprocess_vgg16(X_train)\n",
        "X_test_vgg16 = preprocess_vgg16(X_test)\n",
        "\n",
        "X_train_mobilenetv2 = preprocess_mobilenetv2(X_train)\n",
        "X_test_mobilenetv2 = preprocess_mobilenetv2(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaz94rVB8xtI"
      },
      "source": [
        "## 2. Model Preparation\n",
        "Load and modify pre-trained models to fit the CIFAR-100 classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBs9PdAu8xtI"
      },
      "source": [
        "### 2.1 Using ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy0srMxN8xtI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Load pre-trained ResNet50 model without the top layer\n",
        "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model_resnet50.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(100, activation='softmax')(x)\n",
        "\n",
        "model_resnet50 = Model(inputs=base_model_resnet50.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model_resnet50.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_resnet50.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3ZpE618xtI"
      },
      "source": [
        "### 2.2 Using VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoOfgJMD8xtI",
        "outputId": "6d461319-2d64-49e2-ced1-0f70325d3ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# Load pre-trained VGG16 model without the top layer\n",
        "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "# Add new layers\n",
        "x = GlobalAveragePooling2D()(base_model_vgg16.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(100, activation='softmax')(x)\n",
        "model_vgg16 = Model(inputs=base_model_vgg16.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model_vgg16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_vgg16.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPvKjypT8xtJ"
      },
      "source": [
        "### 2.3 Using MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVE5QT-r8xtJ",
        "outputId": "610dfc5a-c2dc-493d-96e9-94d1cdfccada"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-e5714e7ffe5d>:4: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model_mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Load pre-trained MobileNetV2 model without the top layer\n",
        "base_model_mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "# Add new layers\n",
        "x = GlobalAveragePooling2D()(base_model_mobilenetv2.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(100, activation='softmax')(x)\n",
        "model_mobilenetv2 = Model(inputs=base_model_mobilenetv2.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model_mobilenetv2.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_mobilenetv2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4LO5ynU8xtJ"
      },
      "source": [
        "## 3. Fine-Tuning and Training\n",
        "Unfreeze some of the top layers of the pre-trained models and continue training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ElWybb8xtJ",
        "outputId": "db50a9ad-57e7-44d3-dfb9-13ac4a4f5611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1762s\u001b[0m 1s/step - accuracy: 0.2766 - loss: 3.1240 - val_accuracy: 0.3964 - val_loss: 2.3867\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1734s\u001b[0m 1s/step - accuracy: 0.4549 - loss: 2.0628 - val_accuracy: 0.4090 - val_loss: 2.3536\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1756s\u001b[0m 1s/step - accuracy: 0.5413 - loss: 1.6667 - val_accuracy: 0.4465 - val_loss: 2.2915\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1757s\u001b[0m 1s/step - accuracy: 0.6180 - loss: 1.3439 - val_accuracy: 0.4525 - val_loss: 2.3533\n",
            "Epoch 5/10\n",
            "\u001b[1m 126/1563\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25:26\u001b[0m 1s/step - accuracy: 0.7167 - loss: 0.9616"
          ]
        }
      ],
      "source": [
        "# Example of unfreezing top layers of ResNet50\n",
        "for layer in model_resnet50.layers[:143]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in model_resnet50.layers[143:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "history_resnet50 = model_resnet50.fit(X_train_resnet50, y_train, epochs=10, validation_data=(X_test_resnet50, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAJbqP6T8xtJ"
      },
      "source": [
        "## 4. Model Evaluation\n",
        "Evaluate each model on the test dataset to compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyEKFHnS8xtJ"
      },
      "outputs": [],
      "source": [
        "acc_resnet50 = model_resnet50.evaluate(X_test_resnet50, y_test)[1]\n",
        "acc_vgg16 = model_vgg16.evaluate(X_test_vgg16, y_test)[1]\n",
        "acc_mobilenetv2 = model_mobilenetv2.evaluate(X_test_mobilenetv2, y_test)[1]\n",
        "\n",
        "print(f'ResNet50 Accuracy: {acc_resnet50:.2f}')\n",
        "print(f'VGG16 Accuracy: {acc_vgg16:.2f}')\n",
        "print(f'MobileNetV2 Accuracy: {acc_mobilenetv2:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDna3lvK8xtJ"
      },
      "source": [
        "## 5. Conclusion\n",
        "Summarize the findings, discuss the effectiveness of transfer learning for this task, and suggest further improvements or experiments."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}